/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
[32m2025-10-31 02:27:00.221[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m295[0m - [1mVerbosity set to INFO[0m
[32m2025-10-31 02:27:00.221[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m295[0m - [1mVerbosity set to INFO[0m
[32m2025-10-31 02:27:00.221[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m295[0m - [1mVerbosity set to INFO[0m
[32m2025-10-31 02:27:00.222[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m295[0m - [1mVerbosity set to INFO[0m
[W1031 02:27:00.208501769 Utils.hpp:164] Warning: Environment variable NCCL_BLOCKING_WAIT is deprecated; use TORCH_NCCL_BLOCKING_WAIT instead (function operator())
[W1031 02:27:00.208503609 Utils.hpp:164] Warning: Environment variable NCCL_BLOCKING_WAIT is deprecated; use TORCH_NCCL_BLOCKING_WAIT instead (function operator())
[W1031 02:27:00.208510120 Utils.hpp:164] Warning: Environment variable NCCL_BLOCKING_WAIT is deprecated; use TORCH_NCCL_BLOCKING_WAIT instead (function operator())
[W1031 02:27:00.208634692 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[W1031 02:27:00.208649566 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[W1031 02:27:00.208684373 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[W1031 02:27:00.209301112 Utils.hpp:164] Warning: Environment variable NCCL_BLOCKING_WAIT is deprecated; use TORCH_NCCL_BLOCKING_WAIT instead (function operator())
[W1031 02:27:00.209387295 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[32m2025-10-31 02:27:00.732[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m378[0m - [1mEvaluation tracker args: {'output_path': 'logs/20251031'}[0m
[32m2025-10-31 02:27:00.732[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m467[0m - [1mSelected Tasks: ['blink_spatial'][0m
[32m2025-10-31 02:27:00.747[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36msimple_evaluate[0m:[36m155[0m - [1mSetting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234[0m
[32m2025-10-31 02:27:00.802[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m378[0m - [1mEvaluation tracker args: {'output_path': 'logs/20251031'}[0m
[32m2025-10-31 02:27:00.802[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m467[0m - [1mSelected Tasks: ['blink_spatial'][0m
[32m2025-10-31 02:27:00.804[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36msimple_evaluate[0m:[36m155[0m - [1mSetting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234[0m
[32m2025-10-31 02:27:00.812[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m378[0m - [1mEvaluation tracker args: {'output_path': 'logs/20251031'}[0m
[32m2025-10-31 02:27:00.812[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m467[0m - [1mSelected Tasks: ['blink_spatial'][0m
[32m2025-10-31 02:27:00.813[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36msimple_evaluate[0m:[36m155[0m - [1mSetting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234[0m
[32m2025-10-31 02:27:00.819[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m378[0m - [1mEvaluation tracker args: {'output_path': 'logs/20251031'}[0m
[32m2025-10-31 02:27:00.819[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m467[0m - [1mSelected Tasks: ['blink_spatial'][0m
[32m2025-10-31 02:27:00.821[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36msimple_evaluate[0m:[36m155[0m - [1mSetting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234[0m
Warning: FlashAttention 3 is not available, falling back to PyTorch's scaled_dot_product_attention
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[32m2025-10-31 02:27:12.449[0m | [1mINFO    [0m | [36mlmms_eval.models.vgllm[0m:[36m__init__[0m:[36m86[0m - [1mUsing Qwen2_5_VLForConditionalGenerationWithVGGT[0m
Warning: FlashAttention 3 is not available, falling back to PyTorch's scaled_dot_product_attention
[32m2025-10-31 02:27:12.554[0m | [1mINFO    [0m | [36mlmms_eval.models.vgllm[0m:[36m__init__[0m:[36m86[0m - [1mUsing Qwen2_5_VLForConditionalGenerationWithVGGT[0m
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Warning: FlashAttention 3 is not available, falling back to PyTorch's scaled_dot_product_attention
[32m2025-10-31 02:27:15.400[0m | [1mINFO    [0m | [36mlmms_eval.models.vgllm[0m:[36m__init__[0m:[36m86[0m - [1mUsing Qwen2_5_VLForConditionalGenerationWithVGGT[0m
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Warning: FlashAttention 3 is not available, falling back to PyTorch's scaled_dot_product_attention
[32m2025-10-31 02:27:17.074[0m | [1mINFO    [0m | [36mlmms_eval.models.vgllm[0m:[36m__init__[0m:[36m86[0m - [1mUsing Qwen2_5_VLForConditionalGenerationWithVGGT[0m
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:11<00:23, 11.60s/it]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:11<00:23, 11.61s/it]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:08<00:17,  8.87s/it]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:07<00:14,  7.20s/it]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:21<00:10, 10.45s/it]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:18<00:09,  9.36s/it]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:16<00:08,  8.67s/it]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:21<00:10, 10.49s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:22<00:00,  6.28s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:22<00:00,  7.52s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:19<00:00,  5.66s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:18<00:00,  5.29s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:22<00:00,  6.28s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:19<00:00,  6.61s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:22<00:00,  7.53s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:18<00:00,  6.06s/it]

Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "/remote-home/haohh/_cvpr2025/VG-LLM/src/lmms_eval/__main__.py", line 330, in cli_evaluate
    results, samples = cli_evaluate_single(args)
  File "/remote-home/haohh/_cvpr2025/VG-LLM/src/lmms_eval/__main__.py", line 330, in cli_evaluate
    results, samples = cli_evaluate_single(args)
  File "/remote-home/haohh/_cvpr2025/VG-LLM/src/lmms_eval/__main__.py", line 330, in cli_evaluate
    results, samples = cli_evaluate_single(args)
  File "/remote-home/haohh/_cvpr2025/VG-LLM/src/lmms_eval/__main__.py", line 330, in cli_evaluate
    results, samples = cli_evaluate_single(args)
  File "/remote-home/haohh/_cvpr2025/VG-LLM/src/lmms_eval/__main__.py", line 471, in cli_evaluate_single
    results = evaluator.simple_evaluate(
  File "/remote-home/haohh/_cvpr2025/VG-LLM/src/lmms_eval/__main__.py", line 471, in cli_evaluate_single
    results = evaluator.simple_evaluate(
  File "/remote-home/haohh/_cvpr2025/VG-LLM/src/lmms_eval/__main__.py", line 471, in cli_evaluate_single
    results = evaluator.simple_evaluate(
  File "/remote-home/haohh/_cvpr2025/VG-LLM/src/lmms_eval/__main__.py", line 471, in cli_evaluate_single
    results = evaluator.simple_evaluate(
  File "/remote-home/haohh/_cvpr2025/VG-LLM/src/lmms_eval/utils.py", line 533, in _wrapper
    return fn(*args, **kwargs)
  File "/remote-home/haohh/_cvpr2025/VG-LLM/src/lmms_eval/utils.py", line 533, in _wrapper
    return fn(*args, **kwargs)
  File "/remote-home/haohh/_cvpr2025/VG-LLM/src/lmms_eval/utils.py", line 533, in _wrapper
    return fn(*args, **kwargs)
  File "/remote-home/haohh/_cvpr2025/VG-LLM/src/lmms_eval/utils.py", line 533, in _wrapper
    return fn(*args, **kwargs)
  File "/remote-home/haohh/_cvpr2025/VG-LLM/src/lmms_eval/evaluator.py", line 176, in simple_evaluate
    lm = lmms_eval.models.get_model(model).create_from_arg_string(
  File "/remote-home/haohh/_cvpr2025/VG-LLM/src/lmms_eval/evaluator.py", line 176, in simple_evaluate
    lm = lmms_eval.models.get_model(model).create_from_arg_string(
  File "/remote-home/haohh/_cvpr2025/VG-LLM/src/lmms_eval/evaluator.py", line 176, in simple_evaluate
    lm = lmms_eval.models.get_model(model).create_from_arg_string(
  File "/remote-home/haohh/_cvpr2025/VG-LLM/src/lmms_eval/evaluator.py", line 176, in simple_evaluate
    lm = lmms_eval.models.get_model(model).create_from_arg_string(
  File "/remote-home/haohh/_cvpr2025/VG-LLM/src/lmms_eval/api/model.py", line 110, in create_from_arg_string
    return cls(**args, **args2)
  File "/remote-home/haohh/_cvpr2025/VG-LLM/src/lmms_eval/api/model.py", line 110, in create_from_arg_string
    return cls(**args, **args2)
  File "/remote-home/haohh/_cvpr2025/VG-LLM/src/lmms_eval/api/model.py", line 110, in create_from_arg_string
    return cls(**args, **args2)
  File "/remote-home/haohh/_cvpr2025/VG-LLM/src/lmms_eval/api/model.py", line 110, in create_from_arg_string
    return cls(**args, **args2)
  File "/remote-home/haohh/_cvpr2025/VG-LLM/src/lmms_eval/models/vgllm.py", line 103, in __init__
    self.processor = AutoProcessor.from_pretrained(pretrained, max_pixels=max_pixels, min_pixels=min_pixels, padding_side="left")
  File "/remote-home/haohh/_cvpr2025/VG-LLM/src/lmms_eval/models/vgllm.py", line 103, in __init__
    self.processor = AutoProcessor.from_pretrained(pretrained, max_pixels=max_pixels, min_pixels=min_pixels, padding_side="left")
  File "/remote-home/haohh/_cvpr2025/VG-LLM/src/lmms_eval/models/vgllm.py", line 103, in __init__
    self.processor = AutoProcessor.from_pretrained(pretrained, max_pixels=max_pixels, min_pixels=min_pixels, padding_side="left")
  File "/remote-home/haohh/_cvpr2025/VG-LLM/src/lmms_eval/models/vgllm.py", line 103, in __init__
    self.processor = AutoProcessor.from_pretrained(pretrained, max_pixels=max_pixels, min_pixels=min_pixels, padding_side="left")
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/models/auto/processing_auto.py", line 350, in from_pretrained
    return PROCESSOR_MAPPING[type(config)].from_pretrained(pretrained_model_name_or_path, **kwargs)
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/models/auto/processing_auto.py", line 350, in from_pretrained
    return PROCESSOR_MAPPING[type(config)].from_pretrained(pretrained_model_name_or_path, **kwargs)
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/models/auto/processing_auto.py", line 350, in from_pretrained
    return PROCESSOR_MAPPING[type(config)].from_pretrained(pretrained_model_name_or_path, **kwargs)
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/models/auto/processing_auto.py", line 350, in from_pretrained
    return PROCESSOR_MAPPING[type(config)].from_pretrained(pretrained_model_name_or_path, **kwargs)
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/processing_utils.py", line 1070, in from_pretrained
    args = cls._get_arguments_from_pretrained(pretrained_model_name_or_path, **kwargs)
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/processing_utils.py", line 1070, in from_pretrained
    args = cls._get_arguments_from_pretrained(pretrained_model_name_or_path, **kwargs)
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/processing_utils.py", line 1070, in from_pretrained
    args = cls._get_arguments_from_pretrained(pretrained_model_name_or_path, **kwargs)
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/processing_utils.py", line 1070, in from_pretrained
    args = cls._get_arguments_from_pretrained(pretrained_model_name_or_path, **kwargs)
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/processing_utils.py", line 1134, in _get_arguments_from_pretrained
    args.append(attribute_class.from_pretrained(pretrained_model_name_or_path, **kwargs))
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/processing_utils.py", line 1134, in _get_arguments_from_pretrained
    args.append(attribute_class.from_pretrained(pretrained_model_name_or_path, **kwargs))
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/processing_utils.py", line 1134, in _get_arguments_from_pretrained
    args.append(attribute_class.from_pretrained(pretrained_model_name_or_path, **kwargs))
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/processing_utils.py", line 1134, in _get_arguments_from_pretrained
    args.append(attribute_class.from_pretrained(pretrained_model_name_or_path, **kwargs))
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/models/auto/image_processing_auto.py", line 465, in from_pretrained
    raise initial_exception
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/models/auto/image_processing_auto.py", line 465, in from_pretrained
    raise initial_exception
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/models/auto/image_processing_auto.py", line 465, in from_pretrained
    raise initial_exception
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/models/auto/image_processing_auto.py", line 465, in from_pretrained
    raise initial_exception
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/models/auto/image_processing_auto.py", line 447, in from_pretrained
    config_dict, _ = ImageProcessingMixin.get_image_processor_dict(
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/models/auto/image_processing_auto.py", line 447, in from_pretrained
    config_dict, _ = ImageProcessingMixin.get_image_processor_dict(
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/models/auto/image_processing_auto.py", line 447, in from_pretrained
    config_dict, _ = ImageProcessingMixin.get_image_processor_dict(
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/models/auto/image_processing_auto.py", line 447, in from_pretrained
    config_dict, _ = ImageProcessingMixin.get_image_processor_dict(
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/image_processing_base.py", line 341, in get_image_processor_dict
    resolved_image_processor_file = cached_file(
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/image_processing_base.py", line 341, in get_image_processor_dict
    resolved_image_processor_file = cached_file(
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/image_processing_base.py", line 341, in get_image_processor_dict
    resolved_image_processor_file = cached_file(
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/image_processing_base.py", line 341, in get_image_processor_dict
    resolved_image_processor_file = cached_file(
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/utils/hub.py", line 266, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/utils/hub.py", line 266, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/utils/hub.py", line 266, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/utils/hub.py", line 266, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/utils/hub.py", line 381, in cached_files
    raise EnvironmentError(
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/utils/hub.py", line 381, in cached_files
    raise EnvironmentError(
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/utils/hub.py", line 381, in cached_files
    raise EnvironmentError(
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/utils/hub.py", line 381, in cached_files
    raise EnvironmentError(
OSError: /remote-home/haohh/_cvpr2025/VG-LLM/debug_output/checkpoint-67000 does not appear to have a file named preprocessor_config.json. Checkout 'https://huggingface.co//remote-home/haohh/_cvpr2025/VG-LLM/debug_output/checkpoint-67000/tree/main' for available files.
OSError: /remote-home/haohh/_cvpr2025/VG-LLM/debug_output/checkpoint-67000 does not appear to have a file named preprocessor_config.json. Checkout 'https://huggingface.co//remote-home/haohh/_cvpr2025/VG-LLM/debug_output/checkpoint-67000/tree/main' for available files.
OSError: /remote-home/haohh/_cvpr2025/VG-LLM/debug_output/checkpoint-67000 does not appear to have a file named preprocessor_config.json. Checkout 'https://huggingface.co//remote-home/haohh/_cvpr2025/VG-LLM/debug_output/checkpoint-67000/tree/main' for available files.
OSError: /remote-home/haohh/_cvpr2025/VG-LLM/debug_output/checkpoint-67000 does not appear to have a file named preprocessor_config.json. Checkout 'https://huggingface.co//remote-home/haohh/_cvpr2025/VG-LLM/debug_output/checkpoint-67000/tree/main' for available files.
[32m2025-10-31 02:27:35.741[0m | [31m[1mERROR   [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m349[0m - [31m[1mError during evaluation: /remote-home/haohh/_cvpr2025/VG-LLM/debug_output/checkpoint-67000 does not appear to have a file named preprocessor_config.json. Checkout 'https://huggingface.co//remote-home/haohh/_cvpr2025/VG-LLM/debug_output/checkpoint-67000/tree/main' for available files.. Please set `--verbosity=DEBUG` to get more information.[0m
[32m2025-10-31 02:27:35.741[0m | [31m[1mERROR   [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m349[0m - [31m[1mError during evaluation: /remote-home/haohh/_cvpr2025/VG-LLM/debug_output/checkpoint-67000 does not appear to have a file named preprocessor_config.json. Checkout 'https://huggingface.co//remote-home/haohh/_cvpr2025/VG-LLM/debug_output/checkpoint-67000/tree/main' for available files.. Please set `--verbosity=DEBUG` to get more information.[0m
[32m2025-10-31 02:27:35.741[0m | [31m[1mERROR   [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m349[0m - [31m[1mError during evaluation: /remote-home/haohh/_cvpr2025/VG-LLM/debug_output/checkpoint-67000 does not appear to have a file named preprocessor_config.json. Checkout 'https://huggingface.co//remote-home/haohh/_cvpr2025/VG-LLM/debug_output/checkpoint-67000/tree/main' for available files.. Please set `--verbosity=DEBUG` to get more information.[0m
[32m2025-10-31 02:27:35.741[0m | [31m[1mERROR   [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m349[0m - [31m[1mError during evaluation: /remote-home/haohh/_cvpr2025/VG-LLM/debug_output/checkpoint-67000 does not appear to have a file named preprocessor_config.json. Checkout 'https://huggingface.co//remote-home/haohh/_cvpr2025/VG-LLM/debug_output/checkpoint-67000/tree/main' for available files.. Please set `--verbosity=DEBUG` to get more information.[0m
[rank0]:[W1031 02:27:36.244937340 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
