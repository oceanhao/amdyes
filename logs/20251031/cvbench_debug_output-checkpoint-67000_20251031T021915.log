/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
[32m2025-10-31 02:20:09.896[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m295[0m - [1mVerbosity set to INFO[0m
[32m2025-10-31 02:20:09.896[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m295[0m - [1mVerbosity set to INFO[0m
[32m2025-10-31 02:20:09.896[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m295[0m - [1mVerbosity set to INFO[0m
[32m2025-10-31 02:20:09.896[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m295[0m - [1mVerbosity set to INFO[0m
[W1031 02:20:09.884247272 Utils.hpp:164] Warning: Environment variable NCCL_BLOCKING_WAIT is deprecated; use TORCH_NCCL_BLOCKING_WAIT instead (function operator())
[W1031 02:20:09.884262859 Utils.hpp:164] Warning: Environment variable NCCL_BLOCKING_WAIT is deprecated; use TORCH_NCCL_BLOCKING_WAIT instead (function operator())
[W1031 02:20:09.884255416 Utils.hpp:164] Warning: Environment variable NCCL_BLOCKING_WAIT is deprecated; use TORCH_NCCL_BLOCKING_WAIT instead (function operator())
[W1031 02:20:09.884378339 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[W1031 02:20:09.884395504 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[W1031 02:20:09.884424857 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[W1031 02:20:09.885189569 Utils.hpp:164] Warning: Environment variable NCCL_BLOCKING_WAIT is deprecated; use TORCH_NCCL_BLOCKING_WAIT instead (function operator())
[W1031 02:20:09.885285228 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[32m2025-10-31 02:20:10.397[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m378[0m - [1mEvaluation tracker args: {'output_path': 'logs/20251031'}[0m
[32m2025-10-31 02:20:10.397[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m467[0m - [1mSelected Tasks: ['cvbench'][0m
[32m2025-10-31 02:20:10.434[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36msimple_evaluate[0m:[36m155[0m - [1mSetting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234[0m
[32m2025-10-31 02:20:10.460[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m378[0m - [1mEvaluation tracker args: {'output_path': 'logs/20251031'}[0m
[32m2025-10-31 02:20:10.460[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m467[0m - [1mSelected Tasks: ['cvbench'][0m
[32m2025-10-31 02:20:10.462[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36msimple_evaluate[0m:[36m155[0m - [1mSetting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234[0m
[32m2025-10-31 02:20:10.482[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m378[0m - [1mEvaluation tracker args: {'output_path': 'logs/20251031'}[0m
[32m2025-10-31 02:20:10.482[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m467[0m - [1mSelected Tasks: ['cvbench'][0m
[32m2025-10-31 02:20:10.484[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36msimple_evaluate[0m:[36m155[0m - [1mSetting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234[0m
[32m2025-10-31 02:20:10.499[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m378[0m - [1mEvaluation tracker args: {'output_path': 'logs/20251031'}[0m
[32m2025-10-31 02:20:10.500[0m | [1mINFO    [0m | [36m__main__[0m:[36mcli_evaluate_single[0m:[36m467[0m - [1mSelected Tasks: ['cvbench'][0m
[32m2025-10-31 02:20:10.501[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36msimple_evaluate[0m:[36m155[0m - [1mSetting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234[0m
Warning: FlashAttention 3 is not available, falling back to PyTorch's scaled_dot_product_attentionWarning: FlashAttention 3 is not available, falling back to PyTorch's scaled_dot_product_attentionWarning: FlashAttention 3 is not available, falling back to PyTorch's scaled_dot_product_attention


Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[32m2025-10-31 02:20:15.793[0m | [1mINFO    [0m | [36mlmms_eval.models.vgllm[0m:[36m__init__[0m:[36m86[0m - [1mUsing Qwen2_5_VLForConditionalGenerationWithVGGT[0m
[32m2025-10-31 02:20:15.793[0m | [1mINFO    [0m | [36mlmms_eval.models.vgllm[0m:[36m__init__[0m:[36m86[0m - [1mUsing Qwen2_5_VLForConditionalGenerationWithVGGT[0m
[32m2025-10-31 02:20:15.793[0m | [1mINFO    [0m | [36mlmms_eval.models.vgllm[0m:[36m__init__[0m:[36m86[0m - [1mUsing Qwen2_5_VLForConditionalGenerationWithVGGT[0m
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Warning: FlashAttention 3 is not available, falling back to PyTorch's scaled_dot_product_attention
[32m2025-10-31 02:20:16.740[0m | [1mINFO    [0m | [36mlmms_eval.models.vgllm[0m:[36m__init__[0m:[36m86[0m - [1mUsing Qwen2_5_VLForConditionalGenerationWithVGGT[0m
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:11<00:23, 11.66s/it]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:12<00:24, 12.47s/it]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:12<00:24, 12.47s/it]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:12<00:24, 12.47s/it]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:21<00:10, 10.72s/it]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:22<00:10, 10.76s/it]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:22<00:10, 10.75s/it]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:21<00:10, 10.45s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:23<00:00,  6.39s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:23<00:00,  7.74s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:23<00:00,  6.40s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:22<00:00,  6.23s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:23<00:00,  6.39s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:23<00:00,  7.74s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:22<00:00,  7.49s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:23<00:00,  7.74s/it]
Traceback (most recent call last):
Traceback (most recent call last):
  File "/remote-home/haohh/_cvpr2025/VG-LLM/src/lmms_eval/__main__.py", line 330, in cli_evaluate
    results, samples = cli_evaluate_single(args)
  File "/remote-home/haohh/_cvpr2025/VG-LLM/src/lmms_eval/__main__.py", line 330, in cli_evaluate
    results, samples = cli_evaluate_single(args)
  File "/remote-home/haohh/_cvpr2025/VG-LLM/src/lmms_eval/__main__.py", line 471, in cli_evaluate_single
    results = evaluator.simple_evaluate(
  File "/remote-home/haohh/_cvpr2025/VG-LLM/src/lmms_eval/__main__.py", line 471, in cli_evaluate_single
    results = evaluator.simple_evaluate(
  File "/remote-home/haohh/_cvpr2025/VG-LLM/src/lmms_eval/utils.py", line 533, in _wrapper
    return fn(*args, **kwargs)
  File "/remote-home/haohh/_cvpr2025/VG-LLM/src/lmms_eval/utils.py", line 533, in _wrapper
    return fn(*args, **kwargs)
  File "/remote-home/haohh/_cvpr2025/VG-LLM/src/lmms_eval/evaluator.py", line 176, in simple_evaluate
    lm = lmms_eval.models.get_model(model).create_from_arg_string(
  File "/remote-home/haohh/_cvpr2025/VG-LLM/src/lmms_eval/evaluator.py", line 176, in simple_evaluate
    lm = lmms_eval.models.get_model(model).create_from_arg_string(
  File "/remote-home/haohh/_cvpr2025/VG-LLM/src/lmms_eval/api/model.py", line 110, in create_from_arg_string
    return cls(**args, **args2)
  File "/remote-home/haohh/_cvpr2025/VG-LLM/src/lmms_eval/api/model.py", line 110, in create_from_arg_string
    return cls(**args, **args2)
  File "/remote-home/haohh/_cvpr2025/VG-LLM/src/lmms_eval/models/vgllm.py", line 103, in __init__
    self.processor = AutoProcessor.from_pretrained(pretrained, max_pixels=max_pixels, min_pixels=min_pixels, padding_side="left")
  File "/remote-home/haohh/_cvpr2025/VG-LLM/src/lmms_eval/models/vgllm.py", line 103, in __init__
    self.processor = AutoProcessor.from_pretrained(pretrained, max_pixels=max_pixels, min_pixels=min_pixels, padding_side="left")
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/models/auto/processing_auto.py", line 350, in from_pretrained
    return PROCESSOR_MAPPING[type(config)].from_pretrained(pretrained_model_name_or_path, **kwargs)
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/models/auto/processing_auto.py", line 350, in from_pretrained
    return PROCESSOR_MAPPING[type(config)].from_pretrained(pretrained_model_name_or_path, **kwargs)
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/processing_utils.py", line 1070, in from_pretrained
    args = cls._get_arguments_from_pretrained(pretrained_model_name_or_path, **kwargs)
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/processing_utils.py", line 1070, in from_pretrained
    args = cls._get_arguments_from_pretrained(pretrained_model_name_or_path, **kwargs)
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/processing_utils.py", line 1134, in _get_arguments_from_pretrained
    args.append(attribute_class.from_pretrained(pretrained_model_name_or_path, **kwargs))
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/processing_utils.py", line 1134, in _get_arguments_from_pretrained
    args.append(attribute_class.from_pretrained(pretrained_model_name_or_path, **kwargs))
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/models/auto/image_processing_auto.py", line 465, in from_pretrained
    raise initial_exception
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/models/auto/image_processing_auto.py", line 465, in from_pretrained
    raise initial_exception
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/models/auto/image_processing_auto.py", line 447, in from_pretrained
    config_dict, _ = ImageProcessingMixin.get_image_processor_dict(
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/models/auto/image_processing_auto.py", line 447, in from_pretrained
    config_dict, _ = ImageProcessingMixin.get_image_processor_dict(
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/image_processing_base.py", line 341, in get_image_processor_dict
    resolved_image_processor_file = cached_file(
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/image_processing_base.py", line 341, in get_image_processor_dict
    resolved_image_processor_file = cached_file(
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/utils/hub.py", line 266, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/utils/hub.py", line 266, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/utils/hub.py", line 381, in cached_files
    raise EnvironmentError(
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/utils/hub.py", line 381, in cached_files
    raise EnvironmentError(
OSError: /remote-home/haohh/_cvpr2025/VG-LLM/debug_output/checkpoint-67000 does not appear to have a file named preprocessor_config.json. Checkout 'https://huggingface.co//remote-home/haohh/_cvpr2025/VG-LLM/debug_output/checkpoint-67000/tree/main' for available files.
OSError: /remote-home/haohh/_cvpr2025/VG-LLM/debug_output/checkpoint-67000 does not appear to have a file named preprocessor_config.json. Checkout 'https://huggingface.co//remote-home/haohh/_cvpr2025/VG-LLM/debug_output/checkpoint-67000/tree/main' for available files.
Traceback (most recent call last):
Traceback (most recent call last):
  File "/remote-home/haohh/_cvpr2025/VG-LLM/src/lmms_eval/__main__.py", line 330, in cli_evaluate
    results, samples = cli_evaluate_single(args)
  File "/remote-home/haohh/_cvpr2025/VG-LLM/src/lmms_eval/__main__.py", line 471, in cli_evaluate_single
    results = evaluator.simple_evaluate(
  File "/remote-home/haohh/_cvpr2025/VG-LLM/src/lmms_eval/utils.py", line 533, in _wrapper
    return fn(*args, **kwargs)
  File "/remote-home/haohh/_cvpr2025/VG-LLM/src/lmms_eval/evaluator.py", line 176, in simple_evaluate
    lm = lmms_eval.models.get_model(model).create_from_arg_string(
  File "/remote-home/haohh/_cvpr2025/VG-LLM/src/lmms_eval/api/model.py", line 110, in create_from_arg_string
    return cls(**args, **args2)
  File "/remote-home/haohh/_cvpr2025/VG-LLM/src/lmms_eval/__main__.py", line 330, in cli_evaluate
    results, samples = cli_evaluate_single(args)
  File "/remote-home/haohh/_cvpr2025/VG-LLM/src/lmms_eval/models/vgllm.py", line 103, in __init__
    self.processor = AutoProcessor.from_pretrained(pretrained, max_pixels=max_pixels, min_pixels=min_pixels, padding_side="left")
  File "/remote-home/haohh/_cvpr2025/VG-LLM/src/lmms_eval/__main__.py", line 471, in cli_evaluate_single
    results = evaluator.simple_evaluate(
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/models/auto/processing_auto.py", line 350, in from_pretrained
    return PROCESSOR_MAPPING[type(config)].from_pretrained(pretrained_model_name_or_path, **kwargs)
  File "/remote-home/haohh/_cvpr2025/VG-LLM/src/lmms_eval/utils.py", line 533, in _wrapper
    return fn(*args, **kwargs)
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/processing_utils.py", line 1070, in from_pretrained
    args = cls._get_arguments_from_pretrained(pretrained_model_name_or_path, **kwargs)
  File "/remote-home/haohh/_cvpr2025/VG-LLM/src/lmms_eval/evaluator.py", line 176, in simple_evaluate
    lm = lmms_eval.models.get_model(model).create_from_arg_string(
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/processing_utils.py", line 1134, in _get_arguments_from_pretrained
    args.append(attribute_class.from_pretrained(pretrained_model_name_or_path, **kwargs))
  File "/remote-home/haohh/_cvpr2025/VG-LLM/src/lmms_eval/api/model.py", line 110, in create_from_arg_string
    return cls(**args, **args2)
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/models/auto/image_processing_auto.py", line 465, in from_pretrained
    raise initial_exception
  File "/remote-home/haohh/_cvpr2025/VG-LLM/src/lmms_eval/models/vgllm.py", line 103, in __init__
    self.processor = AutoProcessor.from_pretrained(pretrained, max_pixels=max_pixels, min_pixels=min_pixels, padding_side="left")
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/models/auto/image_processing_auto.py", line 447, in from_pretrained
    config_dict, _ = ImageProcessingMixin.get_image_processor_dict(
[32m2025-10-31 02:20:39.731[0m | [31m[1mERROR   [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m349[0m - [31m[1mError during evaluation: /remote-home/haohh/_cvpr2025/VG-LLM/debug_output/checkpoint-67000 does not appear to have a file named preprocessor_config.json. Checkout 'https://huggingface.co//remote-home/haohh/_cvpr2025/VG-LLM/debug_output/checkpoint-67000/tree/main' for available files.. Please set `--verbosity=DEBUG` to get more information.[0m
[32m2025-10-31 02:20:39.731[0m | [31m[1mERROR   [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m349[0m - [31m[1mError during evaluation: /remote-home/haohh/_cvpr2025/VG-LLM/debug_output/checkpoint-67000 does not appear to have a file named preprocessor_config.json. Checkout 'https://huggingface.co//remote-home/haohh/_cvpr2025/VG-LLM/debug_output/checkpoint-67000/tree/main' for available files.. Please set `--verbosity=DEBUG` to get more information.[0m
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/models/auto/processing_auto.py", line 350, in from_pretrained
    return PROCESSOR_MAPPING[type(config)].from_pretrained(pretrained_model_name_or_path, **kwargs)
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/image_processing_base.py", line 341, in get_image_processor_dict
    resolved_image_processor_file = cached_file(
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/processing_utils.py", line 1070, in from_pretrained
    args = cls._get_arguments_from_pretrained(pretrained_model_name_or_path, **kwargs)
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/utils/hub.py", line 266, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/processing_utils.py", line 1134, in _get_arguments_from_pretrained
    args.append(attribute_class.from_pretrained(pretrained_model_name_or_path, **kwargs))
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/utils/hub.py", line 381, in cached_files
    raise EnvironmentError(
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/models/auto/image_processing_auto.py", line 465, in from_pretrained
    raise initial_exception
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/models/auto/image_processing_auto.py", line 447, in from_pretrained
    config_dict, _ = ImageProcessingMixin.get_image_processor_dict(
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/image_processing_base.py", line 341, in get_image_processor_dict
    resolved_image_processor_file = cached_file(
OSError: /remote-home/haohh/_cvpr2025/VG-LLM/debug_output/checkpoint-67000 does not appear to have a file named preprocessor_config.json. Checkout 'https://huggingface.co//remote-home/haohh/_cvpr2025/VG-LLM/debug_output/checkpoint-67000/tree/main' for available files.
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/utils/hub.py", line 266, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
  File "/remote-home/haohh/anaconda3/envs/vgllm/lib/python3.10/site-packages/transformers/utils/hub.py", line 381, in cached_files
    raise EnvironmentError(
OSError: /remote-home/haohh/_cvpr2025/VG-LLM/debug_output/checkpoint-67000 does not appear to have a file named preprocessor_config.json. Checkout 'https://huggingface.co//remote-home/haohh/_cvpr2025/VG-LLM/debug_output/checkpoint-67000/tree/main' for available files.
[32m2025-10-31 02:20:39.732[0m | [31m[1mERROR   [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m349[0m - [31m[1mError during evaluation: /remote-home/haohh/_cvpr2025/VG-LLM/debug_output/checkpoint-67000 does not appear to have a file named preprocessor_config.json. Checkout 'https://huggingface.co//remote-home/haohh/_cvpr2025/VG-LLM/debug_output/checkpoint-67000/tree/main' for available files.. Please set `--verbosity=DEBUG` to get more information.[0m
[32m2025-10-31 02:20:39.732[0m | [31m[1mERROR   [0m | [36m__main__[0m:[36mcli_evaluate[0m:[36m349[0m - [31m[1mError during evaluation: /remote-home/haohh/_cvpr2025/VG-LLM/debug_output/checkpoint-67000 does not appear to have a file named preprocessor_config.json. Checkout 'https://huggingface.co//remote-home/haohh/_cvpr2025/VG-LLM/debug_output/checkpoint-67000/tree/main' for available files.. Please set `--verbosity=DEBUG` to get more information.[0m
[rank0]:[W1031 02:20:40.254466007 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
